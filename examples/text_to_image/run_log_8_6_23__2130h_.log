/home/dhankar/temp/08_23/huggin_face/diff/diffusers/examples/text_to_image/test_1_pipe.py:131: FutureWarning: Accessing config attribute `in_channels` directly via 'UNet2DConditionModel' object attribute is deprecated. Please access 'in_channels' over 'UNet2DConditionModel's config object instead, e.g. 'unet.config.in_channels'.
  latents = torch.randn((batch_size, unet.in_channels, height // 8, width // 8),generator=generator,)
--torch_device1- cpu
--torch_device2- cuda
--type(vae---> <class 'diffusers.models.autoencoder_kl.AutoencoderKL'>
--type(tokenizer---> <class 'transformers.models.clip.tokenization_clip.CLIPTokenizer'>
--type(text_encoder---> <class 'transformers.models.clip.modeling_clip.CLIPTextModel'>
--type(unet---> <class 'diffusers.models.unet_2d_condition.UNet2DConditionModel'>
--type(scheduler---> <class 'diffusers.schedulers.scheduling_unipc_multistep.UniPCMultistepScheduler'>
--torch_device1- cpu
--torch_device2- cuda
--text_input---> {'input_ids': tensor([[49406,  1731, 22975,   525,   320,  8686,  2619, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0]])}
--text_input---> tensor([[49406,  1731, 22975,   525,   320,  8686,  2619, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407,
         49407, 49407, 49407, 49407, 49407, 49407, 49407]])
--text_input--text_input.attention_mask--> tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0]])
--type(text_embeddings--> <class 'torch.Tensor'>
--text_embeddings--> tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],
         [-0.8512,  0.4016,  1.2630,  ..., -2.0346,  0.4913,  0.0713],
         [-1.4644,  0.2633,  1.5454,  ...,  0.6448,  1.0746, -0.1843],
         ...,
         [-1.8343, -0.0850,  0.0342,  ..., -0.8829, -0.2938, -0.1123],
         [-1.8405, -0.0976,  0.0329,  ..., -0.8871, -0.2938, -0.1200],
         [-1.8027, -0.0353,  0.0657,  ..., -0.9518, -0.2578, -0.1262]]])
--type(uncond_embeddings--> <class 'torch.Tensor'>
--uncond_embeddings--> tensor([[[-0.3884,  0.0229, -0.0522,  ..., -0.4899, -0.3066,  0.0675],
         [-0.3711, -1.4497, -0.3401,  ...,  0.9489,  0.1867, -1.1034],
         [-0.5107, -1.4629, -0.2926,  ...,  1.0419,  0.0701, -1.0284],
         ...,
         [ 0.5006, -0.9552, -0.6610,  ...,  1.6013, -1.0622, -0.2191],
         [ 0.4988, -0.9451, -0.6656,  ...,  1.6467, -1.0858, -0.2088],
         [ 0.4923, -0.8124, -0.4912,  ...,  1.6108, -1.0174, -0.2484]]],
       grad_fn=<NativeLayerNormBackward0>)
--type(latents-1----> <class 'torch.Tensor'>
--latents-1----> tensor([[[[-1.1258, -1.1524, -0.2506,  ..., -1.2341,  1.8197, -0.5515],
          [-0.5692,  0.9200,  1.1108,  ...,  1.1648,  0.9234,  1.3873],
          [-0.8834, -0.4189, -0.8048,  ..., -0.9944, -1.1894, -1.1959],
          ...,
          [ 0.0859, -0.3592, -2.4972,  ..., -1.0989, -0.2155,  0.3364],
          [ 0.5901, -0.8325, -1.3715,  ...,  1.0564, -0.1504,  0.7420],
          [ 0.7272, -0.2612,  0.0124,  ..., -3.0357, -1.7288,  0.6020]],

         [[ 1.9476,  1.0077, -0.1007,  ..., -0.1173, -0.6841,  0.5988],
          [-0.2579, -1.0667, -0.7595,  ..., -0.1600,  1.0375,  1.2084],
          [ 1.3706, -0.0510,  2.6697,  ...,  0.1930, -2.0206, -0.5840],
          ...,
          [-1.5910,  1.0099,  0.2331,  ..., -0.5705, -0.8428, -1.2050],
          [-1.6555,  0.7469,  1.6022,  ..., -0.8822,  0.3436, -0.3445],
          [-0.0718,  0.8205, -0.0775,  ..., -0.7476, -1.0687, -0.1856]],

         [[ 0.2652, -0.7908,  0.9808,  ...,  0.4130, -0.7824,  1.7467],
          [-0.0583,  0.9223,  0.5924,  ..., -2.2366, -0.3921,  0.3631],
          [-0.4197, -0.8450, -0.6224,  ..., -0.8636,  0.1449,  1.7647],
          ...,
          [-0.3144,  0.9923,  0.3074,  ..., -0.6925, -1.5328, -1.3741],
          [ 0.4452,  0.9136, -0.2788,  ..., -1.7930,  0.8511, -1.4528],
          [ 0.1486,  0.4138,  0.5233,  ...,  1.2246, -0.9603, -0.6734]],

         [[-1.0890, -0.9528,  0.1688,  ...,  0.4781,  0.6494, -1.2252],
          [-1.9213,  1.1630, -0.1448,  ..., -1.5672,  0.0918, -0.1540],
          [-1.3179, -0.3727, -0.8441,  ..., -1.4757, -1.1799, -0.3072],
          ...,
          [-0.3931,  0.2065, -2.1190,  ..., -0.3143, -0.7680, -0.3209],
          [ 0.9347,  1.1779, -0.5261,  ..., -0.4910,  0.0231, -1.2609],
          [ 0.0426,  0.6799, -0.4928,  ...,  0.0908, -1.3665, -1.0782]]]])
